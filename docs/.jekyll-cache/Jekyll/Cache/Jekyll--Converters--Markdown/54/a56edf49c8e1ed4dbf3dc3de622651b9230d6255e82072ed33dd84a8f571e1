I"<p>For this week, we are going to mainly focus on analyzing the behaviour of the model, and try to understand better the different things that made it work better than the other weeks. With this, we make a list of things that need to be check this week:</p>

<ul>
  <li>Create a new dataset that only covers the right lane of the road</li>
  <li>Understand our PilotNet-like model</li>
  <li>Show and analyze the throttle of the car to see if it is learning something</li>
</ul>

<h2 id="create-a-new-dataset">Create a new dataset</h2>

<p>This task was made mainly to solve the most basic problem at hand, make the car run in its corresponding lane. To do this, the principal idea was to change the whole dataset, and this was because the way we gathered data, was to make the car run a certain amount of time through different starting waypoints. This starting waypoints were selected at random, so if a road had multiple roads, it wouldnâ€™t distinguish wether if he should be on one lane or other. So, by selecting precisely the starting waypoints that correspond to the left lane of each town, we hoped to solve the problem of the car going through the wrong lane.</p>

<p>We balanced our data the best way possible, obtaining the next data distribution.</p>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/town235_followroad_rightlane_big.png" alt="" />
  <figcaption>Histogram of balanced steering data</figcaption>
</figure>

<p>And once we had the data, we were going to train and analyze the model configurations and its behaviour.</p>

<h2 id="understanding-the-model">Understanding the model</h2>

<p>To understand the model, we tried different configurations to a balanced dataset. The configurations went from seeing the effects of the normalization and dropout techniques on the learning process to testing wether to predict only the steering, or the steering and the throttle.</p>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/epoch_loss_model_study.png" alt="" />
  <figcaption>Epoch loss of multiple model configurations</figcaption>
</figure>

<p>The worst learning cases from the epoch_loss graph belongs to the configurations in which we tried to make the model learn only the steering values, taking away the throttle. To add more to this graph, the orange line corresponds to the model we developed on week 19, a model that had a normalization layer between each convolutional layer. Now we know that this wasnâ€™t strictly necessary, by bringing the model closer to the original concept of the PilotNet, we could obtain better results.</p>

<p>Now, on the good size of the graph, the lowest loss was given by a model that neither had normalization, nor dropout in it. Being the best for giving us a good loss value, it didnâ€™t seem to perform well on extreme steering values. Now, trying to find the best possible configuration, the next good model was the one that had normalization on the input layer and dropout layers between the dense layer. This last model seemed to have a better correlation between the groundtruth and the prediction values even thought the loss was higher than the best model. Given this negligible difference between the losses, we decided to go on with the model that uses a normalization layer on the beginning and dropout layers between the dense layers.</p>

<figure class="half">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/20221101-112924_plot_graph_epoch50.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/20221101-123609_plot_graph_epoch50.png" alt="" />
  <figcaption>Groundtruth vs. prediction values of two different model configurations. The </figcaption>
</figure>
:ET