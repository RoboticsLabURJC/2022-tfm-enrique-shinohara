I"<p>This week comes as a good point of inflection because by understanding more about the PilotNet and how it works, it was possible to solve a big chunk of the problems I had this past few weeks. But once again, before we see the results right away, it would nice to check what were the changes that led us to finding a good solution.</p>

<h2 id="the-model-arquitecture">The model arquitecture</h2>

<p>Being one big part of the whole deep learning project, the model was one of the few things we didnâ€™t quite tweak to solve our little problem. This little problem consisted of how we translated the output to the Carla Simulation, this is because the output always gave us values bigger than one. This by itself was the main thing that needed fixing, we werenâ€™t dealing correctly with how the model trained from the input data to the output values. So, once we had that checked, it was the moment to try different configurations with the PilotNet model, and the holy grail of the solution was: normalization.</p>

<p>But by normalizing the test image, we had a model with a pretty big systematic offset between the predictions and the groundtruth that obviously wasnâ€™t learning at all. The next image is an example of the previous model and its prediction over the normalized test image, it showed me that it was certainly learning something, but didnâ€™t correlate with the groundtruth scope of the steering values. So, being quite sure that the normalization was part of the problem, we decided to tamper with the arquitecture of the model.</p>

<figure class="align-center" style="width:100%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/plot_graph_epoch0_prediction_normalized.png" alt="" />
  <figcaption>Graph of the predicted steering values (red) against the groundtruth (green).</figcaption>
</figure>

<p>The normalization part of this whole project was already covered firstly by a BatchNormalization introduced in the first layer of the model, and secondly on the augmentations of the input images. But it resulted to be insufficient for our problem, by having so many parameters from the convolutional layer passed on to the dense layers, it was taken as an idea to scale this parameters by using a normalization layer and once this was added, we checked wether the model was learning and was staying within the expected range of 0-1.</p>

<iframe src="https://giphy.com/embed/GeY8aqy8gF3zPcwGH5" width="600" height="400" frameborder="0" class="align-center" allowfullscreen=""></iframe>
<p></p>

<p>And as we can see from the previous graph, it was! The model was adjusting itself from within the correct range and learning the good weights to adjust to the groundtruth.</p>

<h2 id="training">Training</h2>

<p>The training part stays pretty much the same as the previous week, for we were doing it correctly, not knowing that the solution wasnâ€™t on the dataset itself or the training parameters. By balancing the dataset as we did and training for 120 epochs, finally found an almost good configuration for the follow road task we had for the Carla Simulator.</p>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/balanced_235.png" alt="" />
  <figcaption>Histogram of the balanced dataset</figcaption>
</figure>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/epoch_loss_235_good.png" alt="" />
  <figcaption>Graph of the loss value along 120 epochs</figcaption>
</figure>

<h2 id="results">Results</h2>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/3DyRwm_xttw"></iframe></a>
</figure>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/7jq29fJP9e4"></iframe></a>
</figure>
:ET