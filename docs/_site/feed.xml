<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/2022-tfm-enrique-shinohara/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/2022-tfm-enrique-shinohara/" rel="alternate" type="text/html" /><updated>2022-11-12T19:51:06+01:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/feed.xml</id><title type="html">Robotics Lab URJC</title><subtitle>Programming Robot Intelligence</subtitle><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><entry><title type="html">Week 22 - Subjective vision for a follow-lane task</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-22/" rel="alternate" type="text/html" title="Week 22 - Subjective vision for a follow-lane task" /><published>2022-11-12T00:00:00+01:00</published><updated>2022-11-12T00:00:00+01:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-22</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-22/"><![CDATA[<p>This week we will try to wrap up some major tasks for the follow-lane vehicle we have been developing this past weeks:</p>

<ul>
  <li>First we will make some small improvements to the model to have a fairly good follow-lane car</li>
  <li>Secondly we will record an illustrative video to show how the car behaves in different roads, whether it be good or bad</li>
  <li>Thirdly, we are going to dig into the segmented images provided by the carla simulator</li>
</ul>

<h2 id="improving-little-by-little">Improving little by little</h2>

<p>By trying to improve the car, we aim to fix some minor behaviour problems that were somewhat bothersome. One interesting behaviour was that it veered to the right even though it had a continuous line separating the left lane from the right lane. A possible explanation to why it was doing this, was that we trained it over some data that we always recorded from the rightmost lane. This could be one of the main reasons to why the car will always change lanes to the farmost right lane (always asuming that there is enough space for the car to run over it).</p>

<p>In order to fix this behaviour we did a more thoughtful balancing of our data, with more augmentations and training time. Having all this steps covered we found a pretty good model that was able to stay in the lane most of the time. Some curious behaviour was found when the car steered too much on sharp curves, but this kind of behaviour were only sighted when the car velocity exceeded the appropiate speed for the curve.</p>

<h2 id="image-segmentation">Image segmentation</h2>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="carla" /><category term="dataset" /><category term="pilotnet" /><summary type="html"><![CDATA[This week we will try to wrap up some major tasks for the follow-lane vehicle we have been developing this past weeks:]]></summary></entry><entry><title type="html">Week 21 - Fixing the car behaviour</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-21/" rel="alternate" type="text/html" title="Week 21 - Fixing the car behaviour" /><published>2022-11-10T00:00:00+01:00</published><updated>2022-11-10T00:00:00+01:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-21</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-21/"><![CDATA[<p>This week, our task was to correct the car behaviour for it was steering towards the oncoming lane even thought this is not a desired quality. Many hours were spent on trying different configurations of the model or adding more data to the dataset. None of it seemed to fix this problem, so we dived deep inside the dataset, and found a possible explanation to why the car was veering to the other lanes.</p>

<p>Our principal suspect was found in the third town, where we noticed a complex situation. If we look closer to the next figure, we can see that right before entering the tunel, the lane slightly shifts to the left, making the car turn slightly to the left if it doesn’t want to colision with part of the tunel. At first we could think that this would not be enough to mess with the way the car learns wether it should stay on the lane or if it should change to another one (at least randomly).</p>

<figure class="half">
  <img style="width:60%" src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/town03_complication.png" alt="" />
  <img style="width:40%" src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/town03_complication_visualmap.png" alt="" />
  <figcaption></figcaption>
</figure>

<p>So to check wether this was the problem or not, we changed the whole dataset, by eliminating and recording only the wanted parts of the town 03. Once the data was collected and the trainining finished, the conclusion was that it worked! The car still needed to fix some behaviour towards harder turns or softer turns, but it wasn’t changing lanes randomly, it stayed or even veered to the rightest lane possible as we tried to teach it.</p>

<p>I will save the idea to show a video for the next week, even though the car is behaving pretty good when compared to the previous weeks, it still needs a little more tweaking to achieve the expected behaviour. But that being said, with some more data balancing and model adjustement we could have a good model that follows its respective lane.</p>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="carla" /><category term="dataset" /><category term="pilotnet" /><summary type="html"><![CDATA[This week, our task was to correct the car behaviour for it was steering towards the oncoming lane even thought this is not a desired quality. Many hours were spent on trying different configurations of the model or adding more data to the dataset. None of it seemed to fix this problem, so we dived deep inside the dataset, and found a possible explanation to why the car was veering to the other lanes.]]></summary></entry><entry><title type="html">Week 20 - Model analysis so far</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-20/" rel="alternate" type="text/html" title="Week 20 - Model analysis so far" /><published>2022-11-03T00:00:00+01:00</published><updated>2022-11-03T00:00:00+01:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-20</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-20/"><![CDATA[<p>For this week, we are going to mainly focus on analyzing the behaviour of the model, and try to understand better the different things that made it work better than the other weeks. With this, we make a list of things that need to be check this week:</p>

<ul>
  <li>Create a new dataset that only covers the right lane of the road</li>
  <li>Understand our PilotNet-like model</li>
  <li>Show and analyze the throttle of the car to see if it is learning something</li>
</ul>

<h2 id="create-a-new-dataset">Create a new dataset</h2>

<p>This task was made mainly to solve the most basic problem at hand, make the car run in its corresponding lane. To do this, the principal idea was to change the whole dataset, and this was because the way we gathered data, was to make the car run a certain amount of time through different starting waypoints. This starting waypoints were selected at random, so if a road had multiple roads, it wouldn’t distinguish wether if he should be on one lane or other. So, by selecting precisely the starting waypoints that correspond to the left lane of each town, we hoped to solve the problem of the car going through the wrong lane.</p>

<p>We balanced our data the best way possible, obtaining the next data distribution.</p>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/town235_followroad_rightlane_big.png" alt="" />
  <figcaption>Histogram of balanced steering data</figcaption>
</figure>

<p>And once we had the data, we were going to train and analyze the model configurations and its behaviour.</p>

<h2 id="understanding-the-model">Understanding the model</h2>

<p>To understand the model, we tried different configurations to a balanced dataset. The configurations went from seeing the effects of the normalization and dropout techniques on the learning process to testing wether to predict only the steering, or the steering and the throttle.</p>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/epoch_loss_model_study.png" alt="" />
  <figcaption>Epoch loss of multiple model configurations</figcaption>
</figure>

<p>The worst learning cases from the epoch_loss graph belongs to the configurations in which we tried to make the model learn only the steering values, taking away the throttle. To add more to this graph, the orange line corresponds to the model we developed on week 19, a model that had a normalization layer between each convolutional layer. Now we know that this wasn’t strictly necessary, by bringing the model closer to the original concept of the PilotNet, we could obtain better results.</p>

<p>Now, on the good size of the graph, the lowest loss was given by a model that neither had normalization, nor dropout in it. Being the best for giving us a good loss value, it didn’t seem to perform well on extreme steering values. Now, trying to find the best possible configuration, the next good model was the one that had normalization on the input layer and dropout layers between the dense layer. This last model seemed to have a better correlation between the groundtruth and the prediction values even thought the loss was higher than the best model. Given this negligible difference between the losses, we decided to go on with the model that uses a normalization layer on the beginning and dropout layers between the dense layers.</p>

<figure class="half">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/20221101-112924_plot_graph_epoch50.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/20221101-123609_plot_graph_epoch50.png" alt="" />
  <figcaption>Groundtruth vs. prediction values of two different model configurations.</figcaption>
</figure>

<p>A deeper understanding of why normalization worked when added on each layer or why the dropout is a good option in this case can be found on multiple articles and papers across the internet such as the BatchNormalization <a href="http://proceedings.mlr.press/v37/ioffe15.pdf">paper</a> where they used the same concept of adding normalization on each layer. But this is going to need more time if I want to grasp and correlate some concepts to our problem.</p>

<h2 id="throttle-analysis">Throttle analysis</h2>

<p>A good idea to analyze how the model is doing, would be to not only check how the steering is performing, but how the throttle is also doing on the training phases. To check the distribution of the throttle values, as we can see on the next figure, the throttle behaves by giving it higher values to accelerate, and decreasing it or making it zero to make the car go slower. By checking, we can see that the car accelerates and decelerate a lot, by following the speed signals set on the map. But how is our car going to know the speed limit if we crop the image to the point were the speed sign is not visible.</p>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/town235_histogram_throttle.png" alt="" />
  <figcaption>Histogram of throttle data</figcaption>
</figure>

<p>This question is one that we don’t need to solve right now, given the fact that we can focus on the steering by setting the throttle to a constant value. But we can check wether it predicts according to the expected behaviour.</p>

<iframe src="https://giphy.com/embed/0FjaVbQYUuu32Ns8wJ" width="600" height="400" frameborder="0" class="align-center" allowfullscreen=""></iframe>
<p></p>

<p>The previous plot shows us the groundtruth of the throttle against the predicted values, and as we can see, it oscilates a lot but we need to check if this translates to something meaningful on the simulator.</p>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="carla" /><category term="dataset" /><category term="pilotnet" /><category term="normalization" /><summary type="html"><![CDATA[For this week, we are going to mainly focus on analyzing the behaviour of the model, and try to understand better the different things that made it work better than the other weeks. With this, we make a list of things that need to be check this week:]]></summary></entry><entry><title type="html">Week 19 - Understanding the problem and untangling the knot</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-19/" rel="alternate" type="text/html" title="Week 19 - Understanding the problem and untangling the knot" /><published>2022-10-27T00:00:00+02:00</published><updated>2022-10-27T00:00:00+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-19</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-19/"><![CDATA[<p>This week comes as a good point of inflection because by understanding more about the PilotNet and how it works, it was possible to solve a big chunk of the problems I had this past few weeks. But once again, before we see the results right away, it would nice to check what were the changes that led us to finding a good solution.</p>

<h2 id="the-model-arquitecture">The model arquitecture</h2>

<p>Being one big part of the whole deep learning project, the model was one of the few things we didn’t quite tweak to solve our little problem. This problem consisted of how we translated the output to the Carla Simulation, this has been a big issue because the output always gave us values bigger than one (like values between 100 and 600). This by itself was the main issue that needed fixing for we weren’t dealing correctly with how the model trained from the input data to the output values. So, once we had that checked, it was the moment to try different configurations with the PilotNet model and finally, the holy grail to finding a solution was: normalization.</p>

<p>But by normalizing the test image, we had a model with a pretty big systematic offset between the predictions and the groundtruth that obviously wasn’t learning at all. The next image is an example of the previous model and its prediction over the normalized test image, it showed me that it was certainly learning something, but didn’t correlate with the groundtruth scope of the steering values. So, being quite sure that the normalization was part of the problem, we decided to tamper with the arquitecture of the model.</p>

<figure class="align-center" style="width:100%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/plot_graph_epoch0_prediction_normalized.png" alt="" />
  <figcaption>Graph of the predicted steering values (red) against the groundtruth (green).</figcaption>
</figure>

<p>The normalization part of this project was already covered firstly by a BatchNormalization introduced in the first layer of the model, and secondly on the augmentations of the input images. But it resulted to be insufficient for our problem, by having so many parameters from the convolutional layer passed on to the dense layers, we tried to scale this parameters by using a normalization layer, and once this was added, we checked wether the model was learning and was staying within the expected range of 0-1.</p>

<iframe src="https://giphy.com/embed/GeY8aqy8gF3zPcwGH5" width="600" height="400" frameborder="0" class="align-center" allowfullscreen=""></iframe>
<p></p>

<p>And if we are understanding correctly from the previous graph, it was! The model was adjusting itself from within the correct range and learning the good weights to adjust itself to the groundtruth.</p>

<h2 id="training">Training</h2>

<p>The training part stays pretty much the same as the previous week, for the problem wasn’t there, not knowing that the solution wasn’t on the dataset itself or the training parameters but on the model itself. By balancing the dataset as we did and train it for 120 epochs, finally we found an almost good configuration for the follow road task we had for the Carla Simulator.</p>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/balanced_235.png" alt="" />
  <figcaption>Histogram of the balanced dataset</figcaption>
</figure>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/epoch_loss_235_good.png" alt="" />
  <figcaption>Graph of the loss value along 120 epochs</figcaption>
</figure>

<p>One thing to notice is that after 40 epochs, the loss stabilize, making it good to stop the training earlier instead of running it for 120 epochs.</p>

<h2 id="results">Results</h2>

<p>Finally, the results shown in the next two videos are pretty much self-explanatory, where the first video shows us an easier example in which we teached the car to turn correctly a single curve being the approach from either left or right.</p>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/3DyRwm_xttw"></iframe></a>
</figure>

<p>In this second video, the car will run through three different maps. One of them will be a known map (Town05), a map used as a dataset for training the car, and the other two towns are maps that the car never saw before, for they weren’t used for the training and validation. We can see that it performs really well as expected, noticing that it turns correctly on sharp and on smoother curves.</p>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/7jq29fJP9e4"></iframe></a>
</figure>

<p>On the other hand, as we anticipated when it encounters a junction (Town04), the car is not able to overcome it for we never trained it on this type of situations. Lastly, we can notice that it didn’t stayed on his own lane when running on the Town04. If we try to come up with an explanation, a possible theory is that some of the maps had multiple lanes in one direction. The car never changed lanes in the middle of a run, but by having different spawnpoints from which to start recollecting the dataset, the car might have used the different lanes and therefore it is not able to distinguish if it can run over one lane or not.</p>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="carla" /><category term="dataset" /><category term="pilotnet" /><category term="normalization" /><summary type="html"><![CDATA[This week comes as a good point of inflection because by understanding more about the PilotNet and how it works, it was possible to solve a big chunk of the problems I had this past few weeks. But once again, before we see the results right away, it would nice to check what were the changes that led us to finding a good solution.]]></summary></entry><entry><title type="html">Week 18 - Simplifying and gathering a lot of data</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-18/" rel="alternate" type="text/html" title="Week 18 - Simplifying and gathering a lot of data" /><published>2022-10-14T00:00:00+02:00</published><updated>2022-10-14T00:00:00+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-18</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-18/"><![CDATA[<p>Simplification. That is the goal of our next task, by simplyfing the follow lane, we are going to build up the complexity of the problem. But first, we need to establish a good foundation for our next problems, and this foundation consist of a car capable of doing the same follow lane that it was possible on the 0.9.2 version of the Carla Simulation. One of the main changes resided on the possibility of using an already implemented autopilot instead of using our own (for now). The problem was that this autopilot was designed to randomly run around the roads of a given map, with this we are only adding very complex situations from the beginning such as intersections or junctions (that we need to take them into account, but not now).</p>

<p>So, to simplify the actual task that we are going to teach our car, we need to establish a simple route planner. Luckily, this is doable on our trustworthy Carla Simulation. By adjusting some parameters on the traffic manager on Carla, we can make our car decide to go straight when it encounters this complex road situations. The other problem we have lies on the Towns from which we are taking the data, the issue here is that we need to ensure that we find a route that doesn’t end in a junction, and we can always find a map with a suitable route for our purpose with the exception of Town04, because no matter the route taken in this map, it coincidentally always ends in a junction.</p>

<figure class="half">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/Carla_0913Town04.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/Carla_0913Town05_painted.png" alt="" />
  <figcaption>Bird-eye view of the Towns 04 (left) and 05 (right). It is possible to define a closed route as shown on the Town05, but not on the Town04.</figcaption>
</figure>

<p>To avoid this and for the sake of simplyfing our task of gathering data for our dataset, we decided to change the training data recollection from the Town04 to the Town05, and use the Town01 and Town04 for testing purposes.</p>

<p>Along-side the recollection of a dataset, I stumbled myself with a pretty interesting <a href="https://arxiv.org/pdf/1710.02410.pdf">paper</a> that approached pretty similarly the same task that we are trying to solve right now, an end-to-end autonomous driving system using imitation learning. And the one thing that caught my eye on this work was how easily they approached the addition of weird scenarios, meaning, scenarios where the car veers from the desired behaviour. By simply doing some noise injection during the data collection. With this, we could try an easy way of adding some outliers to our dataset with the hope of a complete dataset for training.</p>

<p>In the next two images, we show a case of noise injection where it is possible to watch how the noise affects the car straight orientation and how it tries to go back to the expected position.</p>

<iframe src="https://giphy.com/embed/xF2zchGZeY41No9ZSp" width="600" height="400" frameborder="0" class="align-center" allowfullscreen=""></iframe>
<p></p>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/noise_injection.png" alt="" />
  <figcaption>Graph of the steering values against the noise injected to it.</figcaption>
</figure>

<h2 id="increasing-our-dataset">Increasing our dataset</h2>

<p>By increasing the dataset, the aim is to improve the model we had up to now, in order to keep trying to make our car learn how to follow roads and take simple turns. By adopting the same thinking as we had before, we once again find ourselves increasing the data we already had, this time from the almost 47.000 images of turning events, we increased it to almost 80.000 images. Balancing our data and starting with the training part, we find that eventhough it is not the ideal result that we want to, we are on the right track. If we take a closer look to how the steering prediction performs when we compared them to the groundtruth, we can see a patern that correlates the two of them. This is a huge step forward knowing that before, when we increased the dataset, this graph didn’t showed us a discernible pattern that correlates the groundtruth and the prediction, only a random set of a scatter plot.</p>

<iframe src="https://giphy.com/embed/bxiOLF0r6plAcKeveK" width="600" height="400" frameborder="0" class="align-center" allowfullscreen=""></iframe>
<p></p>

<p>Weirdly I now find myself on the other side of the coin. Whereas in the previous weeks I was struggling to make the car turn correctly and not having any problem on the straights, this time (as it can be seen during the video) I have a car that is able to turn correctly but is not able keep itself on the road.</p>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/yYJUwIlSEtc"></iframe></a>
</figure>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="carla" /><category term="dataset" /><summary type="html"><![CDATA[Simplification. That is the goal of our next task, by simplyfing the follow lane, we are going to build up the complexity of the problem. But first, we need to establish a good foundation for our next problems, and this foundation consist of a car capable of doing the same follow lane that it was possible on the 0.9.2 version of the Carla Simulation. One of the main changes resided on the possibility of using an already implemented autopilot instead of using our own (for now). The problem was that this autopilot was designed to randomly run around the roads of a given map, with this we are only adding very complex situations from the beginning such as intersections or junctions (that we need to take them into account, but not now).]]></summary></entry><entry><title type="html">Week 17 - Combating imbalanced data</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-17/" rel="alternate" type="text/html" title="Week 17 - Combating imbalanced data" /><published>2022-10-13T00:00:00+02:00</published><updated>2022-10-13T00:00:00+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-17</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-17/"><![CDATA[<p>As a continuation of our current task, we are going to keep trying to make our car follow straight roads and turn on the curves correctly. As a reminder, we already had this feature on the 0.9.2 version of the Carla Simulation, but by upgrading to the 0.9.13 (in order to be able to use more of the latest features and realistic driving physics) the whole model had a little stepback that needed to be revisited. The problem mainly resides on the fundamental changes made to the car physics of the new Carla simulator, with this changes, we needed to create a new model that could learn this behaviour in order to drive correctly on the simulation. So, to resume, we needed to recollect data from the new version for us to train a new model for the follow-lane task, once we had this data we process it so that the model could learn meaningful information, and finally test it to see the results.</p>

<p>First of all, we need a dataset. The dataset we are going to use, is the same as the one we used on the previous post. The only difference is that we increased the “weird” cases such us the turns or strange start positions (such as having the car slightly turned around the yaw) for it to know how to behave on this cases. This was done by doubling the quantity of this “weird” data, where once we had 22.135 images, we increase them to almost 47.000. Another main change we did to the dataset approach, was to not flip the images. This last idea was proposed to me from one of my advisors, and the idea behind it that by flipping the images, we could make the car be able to confront much more cases whether it is left or right turns. But because we are trying to imitate a realistic driving situation, the car would have no problem in changing lanes, whereas if we don’t flip the images, by sacrificing better capabilities to generalize, we are making the car stay on its lane.</p>

<figure class="half">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/histogram_town234_low.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/histogram_town234_low_newcurves_no_flip.png" alt="" />
  <figcaption>Historigram comparison of the flipped images included (left) and the dataset without adding flipped images (right).</figcaption>
</figure>

<figure class="align-center" style="width:50%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/histogram_town234_low_newcurves_no_flip_extreme.png" alt="" />
  <figcaption>Historigram of the non-flipped and balanced dataset</figcaption>
</figure>

<p>Then we put the model to train for 100 epochs, just to see the progress of the training and to try to analyze possible problems with it. One of the things we noticed was how well a good balanced dataset serves our purpose of decreasing the gap between the training set error and the validation set error.</p>

<figure class="align-center" style="width:70%">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/epoch_loss_no_flip.png" alt="" />
  <figcaption>Un-balanced training set (orange), un-balanced validation set (dark blue); balanced training set (red), balanced validation set (light blue)</figcaption>
</figure>

<p>Other thing we noticed, is that by simply increasing the “weird” cases on our dataset wasn’t enough. The loss on our un-balanced validation set, follows almost the same pattern as the one we had on the previous week. Like we said, the main difference training-wise, was seen on the way we balance our data.</p>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/2C-o_6tMh8s"></iframe></a>
</figure>

<p>As we can see from the video, the car is able to follow a straight road but it cannot stay in one lane, given that it was a desirable quality for the car we need to further improve the way we train with this new dataset. Also, we seem to be stuck once again on the curve problem, it is not able to turn correctly, but as we saw from previous experiences, this problem is mainly resolved by increasing (even more) the quantity of turning events in our dataset, as well as the correct balancing of its values.</p>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="carla" /><summary type="html"><![CDATA[As a continuation of our current task, we are going to keep trying to make our car follow straight roads and turn on the curves correctly. As a reminder, we already had this feature on the 0.9.2 version of the Carla Simulation, but by upgrading to the 0.9.13 (in order to be able to use more of the latest features and realistic driving physics) the whole model had a little stepback that needed to be revisited. The problem mainly resides on the fundamental changes made to the car physics of the new Carla simulator, with this changes, we needed to create a new model that could learn this behaviour in order to drive correctly on the simulation. So, to resume, we needed to recollect data from the new version for us to train a new model for the follow-lane task, once we had this data we process it so that the model could learn meaningful information, and finally test it to see the results.]]></summary></entry><entry><title type="html">Week 16 - The solution of every problem is another problem</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-16/" rel="alternate" type="text/html" title="Week 16 - The solution of every problem is another problem" /><published>2022-10-06T00:00:00+02:00</published><updated>2022-10-06T00:00:00+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-16</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-16/"><![CDATA[<p>And just as the problem of turning was fixed, I stumble my self into another problem, but nothing to be afraid of (yet). The simple task of moving from the 0.9.2 version of Carla to the 0.9.13, has proven to be quite a handful of problems given the fact that I am still not able to emulate the same behaviour as the old Carla version and its impressive ability to turn left and right, but to understand and keep trying to find a solution, let us first start from the beginning.</p>

<p>For this week we had to focus on a variety of tasks:</p>
<ul>
  <li>Setting everything up for the new version of the Carla Simulator, such us, packages compatibility for us to keep using the same code used for the 0.9.2 version.</li>
  <li>To enrich our neural network adding the velocity on the training and prediction. Right now we are only using the steering values to learn the behaviour of the car.</li>
  <li>Learn and if possible, implement the <a href="https://arxiv.org/abs/1912.12294">Learning by Cheating</a> paper onto our arquitecture. This should gives us a more robust training method but it requires a slightly different approach as the one taken up to now.</li>
</ul>

<p>To deal with the first two tasks, we needed to collect a bunch of data from the new Carla version. This has to be done because one of the main differences with the new version and the old, as we mentioned on a previous post, resides on the refinement of the car physics. This alone is a feature that aimed to bring closer the simulation to the real world, so it basically changes completely how the car behaves on the simulator and therefore what it learns from it. So we needed to start the process of teaching a neural network from the beginning.</p>

<p>In order to gather our thoughts better, first we need to talk a little about the dataset and the different towns available to us from the 0.9.13 version of the Carla Simulator. The idea we came up with was to collect 30 minutes of autopilot data from the 2, 3 and 4 Town, leaving the Towns 1 and 5 for testing purposes.</p>

<figure class="third">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/Carla_0913Town02.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/Carla_0913Town03.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/Carla_0913Town04.png" alt="" />
  <figcaption>Bird's-eye view of Town02, Town03 and Town04 respectively.</figcaption>
</figure>

<figure class="half">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/Carla_0913Town01.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/Carla_0913Town05.png" alt="" />
  <figcaption>Bird's-eye view of Town01 (left) and Town05 (right).</figcaption>
</figure>

<p>The recollection gave us a total of 93.655 images for training and validation. The problem with using so much data, compared to the 32.674 on the previous version, is that the data balancing process as well as the training steps consume much more resources from our machine to the poin that it automatically kills the process for the lack of computation capability. But for the sake of coming with a solution, we go ahead and balance our data as shown in the next figure.</p>

<figure class="half">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/histogram_town234.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/histogram_town234_low.png" alt="" />
  <figcaption>Historigram of the whole dataset without preprocessing (left) and preprocessed and balanced data (right).</figcaption>
</figure>

<p>Once we have our data balanced we proceed like we did on previous cases, with training the model for the purpose of making the car follow the lane. To train the model, we go ahead and make it learn throught as many epochs as possible, so that we might be able to analyze if it is training correctly or not. One of the main changes done to the parameters, is the learning rate of the training process. We wanted to see how the model adjust its weights along this two different values.</p>

<figure class="half">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/0_0001.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/0_01.png" alt="" />
  <figcaption>Training epoch loss between small learning rate of 0.0001 (left) and big learning rate 0.01 (right)</figcaption>
</figure>

<p>As we can see from the previous graph, the model is barely learning anything, while the training error (orange) is getting lower, the validation error (blue) is much higher. We might be overfitting our data, maybe because of the possibly wrongly balanced data. On the other hand, by increasing the learning rate, we observe a stabilized but similar error on the train and validation data. We could thing good of this training but then again, if we check the scatter plot of the predicted steering values compared to the groundtruth we found the next thing.</p>

<figure class="half">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/scatter_plot_0913_0_0001.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/scatter_plot_0913_0_01.png" alt="" />
  <figcaption>Scatter plot from the 50th epoch, learning rate of 0.0001 (left) and 0.01 (right)</figcaption>
</figure>

<p>While the 0.0001 learning rate gives random prediction as we can see from its distribution (we cannot distinguish any pattern), the 0.01 shows us barely no correlation between the groundtruth and the prediction, proving that it didn’t learn the proper behaviour for steering values.</p>

<p>The fundamental problem with the actual setup of my machine, is that as we talked before, it kills the process before we can see if it is possible for the error to get any lower of it is going to stay the same forever. To try to fix this problem we may have been dragged a few steps back but we will always try to understand and make sense of the issues, finding a suitable solution. For example, one possible way around this, could be to lower the batch size for it to be more computationally friendly, or reduce even more the quantity of data used for training.</p>

<h2 id="bird-eye-view-training">Bird-eye view training</h2>

<p>As the third task, one of my master thesis advisor Sergio, showed me a pretty interesting and renowned paper called <a href="https://arxiv.org/abs/1912.12294">Learning by Cheating</a>. And the premise of this was to make a much easier learning process by using a simple world representation such us the bird-eye view like the one we see in the next video.</p>

<iframe src="https://giphy.com/embed/dX1pygmF5IBoDHV63b" width="150" height="139  " frameborder="0" class="align-center" allowfullscreen=""></iframe>
<p></p>

<p>It is also demostrated by the authors of the paper that this method makes a robust vision-based autonomous driving system, which we thought was worth a try, at least as a “second” priority task for the week. And as such, all the progress I made around this matter consists on reading and understanding the paper, and installing a pretty neat package called <a href="https://github.com/deepsense-ai/carla-birdeye-view">carla_birdeye_view</a> made to take a 2D world representation (bird-eye view) from the Carla Simulator. With this package, I was able to easily collect a bird-eye data with the autopilot from Carla.</p>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="carla" /><summary type="html"><![CDATA[And just as the problem of turning was fixed, I stumble my self into another problem, but nothing to be afraid of (yet). The simple task of moving from the 0.9.2 version of Carla to the 0.9.13, has proven to be quite a handful of problems given the fact that I am still not able to emulate the same behaviour as the old Carla version and its impressive ability to turn left and right, but to understand and keep trying to find a solution, let us first start from the beginning.]]></summary></entry><entry><title type="html">Week 15 - Building momentum</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-15/" rel="alternate" type="text/html" title="Week 15 - Building momentum" /><published>2022-09-28T00:00:00+02:00</published><updated>2022-09-28T00:00:00+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-15</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-15/"><![CDATA[<p>Finally, we have made some visible progress with the car learning how to follow the lane implicitly. To do this the idea is pretty much the same as the previous weeks, to enrich the dataset with more complex situations so that the car is able to handle the straights and the curves of the road. Once we have increased once again the dataset, we have the next composition of a balanced dataset.</p>

<figure style="width:80%" class="align-center">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/histogram_20+curves+weird_extreme_good.png" alt="" />
  <figcaption>Histogram of the steering values used for training</figcaption>
</figure>

<p>In total we end up with around 45.000 images. By adding this complex situations and adjusting the output of the network, this last task has to be done manually, adjusting the range of the output with the range of the Carla simulation to be able to interpret the predictions of the neural network. Once we have all this adjusted, we end up with the next run.</p>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/YDHKA6ymo7s"></iframe></a>
</figure>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/RAjDoJGylo4"></iframe></a>
</figure>

<p>It is interesting to watch some of the behaviour of the car in the previous video, for it has learned how to correct complex scenarios. As an example, in the first video (around the 28 second) once the turn is over, the car heads for the sidewalk, but then abruptly turns to the left straightening itself back to the lane. Trying to remember, previously we added to the dataset some weird start cases were we turned the car some degrees along the yaw so that it could learn how to straight itself back to the lane, and in the example from the video we can appreciate similar behaviour were it tries to overcome this scenario by following the lane accordingly.</p>

<h2 id="what-comes-next">What comes next</h2>

<p>As I keep learning the ropes of machine learning by training a vehicle how to follow a road, a more simple task arise in front of me. I am currently using the 0.9.2 version of the Carla simulation, but it is always a good idea to catch up with the newest developments around the software given that it usually comes with much more functionallity, better documentation and solutions to the machine learning problem and a greater scope regarding the newest technology.</p>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/S2VIP0qumas"></iframe></a>
</figure>

<p>This last version currently is the 0.9.13 and as saw in the video, this version comes with improved vehicle physics, and I emphasize on this because it could be the main reason why the model trained on the 0.9.2 version wouldn’t work on the new one. Basically, we need to shift everything we had to the 0.9.13 and try to test it once more in order to make it work on our machine, for one of the main problems I had when I began my master thesis with this version, was that because it has better graphics and more assets, the cost of running it was higher than the 0.9.2. So, if we tweak again with the configuration, we might end up with the same quality of client-server connection as we have with the 0.9.2 version. But this is a work still in progress…</p>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="carla" /><category term="dataset" /><summary type="html"><![CDATA[Finally, we have made some visible progress with the car learning how to follow the lane implicitly. To do this the idea is pretty much the same as the previous weeks, to enrich the dataset with more complex situations so that the car is able to handle the straights and the curves of the road. Once we have increased once again the dataset, we have the next composition of a balanced dataset.]]></summary></entry><entry><title type="html">Week 14 - Why is it not turning?</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-14/" rel="alternate" type="text/html" title="Week 14 - Why is it not turning?" /><published>2022-09-17T00:00:00+02:00</published><updated>2022-09-17T00:00:00+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-14</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-14/"><![CDATA[<p>Carry on with the task at hand, we still need to figure out why the car is not turning when we increased the dataset with more turning situations. Wasn’t the quantity of increased data enough? More tweaking on the augmentation to see which turning value needs more weight? Even more variability on the dataset?</p>

<p>To tackle this questions and find the solution, an enumeration of where proposed for me by my tutor and advisor. The lines to keep on track right now are:</p>

<ul>
  <li>Introduce more variety onto the dataset</li>
  <li>Measure the behaviour of the network</li>
  <li>Explore other works along the side of a car following a road using neural networks</li>
</ul>

<p>To conclude the exploration part of this week, it is possible to find blogs of people who have tried this problem before with success. As expected, this is just the base when we see the bigger picture (given that we have also in mind to experiment with reinforcement learning), but is a base that we need to “conquer”. Given that this problem is being draged on since the previous week, we need to establish the next route to find the problem, and as one of the tasks at hand, we are going to need to search and measure the neural network and its training process (where the problem will be more likely to be found).</p>

<h2 id="measuring-the-behaviour-of-the-training-process-and-increasing-the-dataset">Measuring the behaviour of the training process and increasing the dataset</h2>

<p>As an experiment, the training was made with 45 epochs, to show us the behaviour of the training with our dataset and see how many epochs would be necessary for our model to not overfit. With this little experiment we simply visualize better that the training stabilize around 10 epochs.</p>

<figure style="width:80%" class="align-center">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/loss_45.png" alt="" />
  <figcaption>Evolution of the error along 45 epochs.</figcaption>
</figure>

<p>One of the possible explanation of why is the car not turning, could be that the car is overfitting on straights, meaning that it is not extracting good, or enough information from the curves. To solve this, we have tried to increase the data, one by adding more curve cases to our dataset, and second by adding weird start cases. This last one has the purpose of giving the car more context of what to do in this strange situations. To do this, we simply rotate the yaw of the car along different points of the road for it to adjust itself and continue on the road as the follow-road algorithm intend it to.</p>

<iframe src="https://giphy.com/embed/VUcpEtOCDNYeebZLcO" width="480" height="360" frameborder="0" class="align-center" allowfullscreen=""></iframe>
<p></p>

<p>By making a scatter plot of the groundtruth and the predicted values of the steering angle, we can have a good understanding of what is happening with the neural network. One of the first thing we can notice, is a certain correlation between this two, meaning that it is certainly learning something. On the bad side, we can comment on two things: one, the visible vertical line in the middle, meaning that the car still oscillates to maintain itself inside the road, otherwise it would learn to follow the road more smoothly, and second, the Y-axis of the plot. This last part is quite tricky, because it means that the network is doing some predictions that don’t correspond to the range of values from which it was trained.</p>

<p>To better understand this, the dataset saved for the training has two values, the steering and the throttle. And while the throttle range from 0 to 1 in the Carla Simulation, the steering range from -1 to 1. This was the way the dataset was saved, but one solution that helped to understand this better is the normalization of the neural network. Normally, the neural networks train better when the data is normalized between 0 and 1, so by changig this step we only need to denormalize the values predicted from the model.</p>

<p>The normalization of the data gives us faster and probably an overall better training of our model, but this doesn’t takes the fact that the output values that the model is giving us doesn’t correspond with the range of values from the input. One solution that helped to improve the results were to try to interpret better how the ouput of the network correlates with the -1 to 1 range of the Carla simulation steering. Once this is tuned correctly, the car shows us a better take on how it handle the curve.</p>

<p>The two videos below shows us how the car performs on two different curves. They both approach it a little differently but both of them show us more improvement on the overall car behaviour.</p>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/ItRGSR-uukg"></iframe></a>
</figure>

<figure class="align-center">
    <a href=""><iframe src="https://www.youtube.com/embed/mY9dlCyR_os"></iframe></a>
</figure>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="carla" /><category term="scatter plot" /><category term="augmentation" /><summary type="html"><![CDATA[Carry on with the task at hand, we still need to figure out why the car is not turning when we increased the dataset with more turning situations. Wasn’t the quantity of increased data enough? More tweaking on the augmentation to see which turning value needs more weight? Even more variability on the dataset?]]></summary></entry><entry><title type="html">Week 13 - Handling the curve</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-13/" rel="alternate" type="text/html" title="Week 13 - Handling the curve" /><published>2022-09-14T00:00:00+02:00</published><updated>2022-09-14T00:00:00+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-13</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-13/"><![CDATA[<p>Stumbling myself with an obstacle, in this week, the work was mainly focused on improving the dataset to handle better the curves. We already had a car that was able to follow the road when it was straight, but as soon as a curve was in front of it, it began to fail. The solution for this problem was discused in the previous post, having a dataset mainly composed of straight roads, the car didn’t have much information on how to handle other cases like curves. So, the solution we took was to increase it, by “recording” only the cases where the car was on a curve we are going to have more data for this cases.</p>

<figure class="half">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/histogram_13+curves.png" alt="" />
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/histogram_13+curves_extreme.png" alt="" />
  <figcaption>Histogram of the original dataset (left) and the oversampled dataset (right) of the steering values.</figcaption>
</figure>

<p>The training was increased to 10 epochs. The next image shows us better, the stabilization of the error on the validation dataset.</p>

<figure style="width:80%" class="align-center">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/epoch_loss_1.png" alt="" />
  <figcaption>Evolution of the error along 10 epochs.</figcaption>
</figure>

<p>The model obtained from this configuration, gives us a car that is able to follow the straight line pretty smoothly without the oscilation we had on the previous model, but it still not capable of taking the curve correctly.</p>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="carla" /><category term="pilotnet" /><category term="dataset" /><summary type="html"><![CDATA[Stumbling myself with an obstacle, in this week, the work was mainly focused on improving the dataset to handle better the curves. We already had a car that was able to follow the road when it was straight, but as soon as a curve was in front of it, it began to fail. The solution for this problem was discused in the previous post, having a dataset mainly composed of straight roads, the car didn’t have much information on how to handle other cases like curves. So, the solution we took was to increase it, by “recording” only the cases where the car was on a curve we are going to have more data for this cases.]]></summary></entry></feed>