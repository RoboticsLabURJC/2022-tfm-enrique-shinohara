<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/2022-tfm-enrique-shinohara/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/2022-tfm-enrique-shinohara/" rel="alternate" type="text/html" /><updated>2022-06-27T12:41:57+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/feed.xml</id><title type="html">Robotics Lab URJC</title><subtitle>Programming Robot Intelligence</subtitle><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><entry><title type="html">Week 2</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-2/" rel="alternate" type="text/html" title="Week 2" /><published>2022-06-27T00:00:00+02:00</published><updated>2022-06-27T00:00:00+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-2</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-2/"><![CDATA[<video width="480" height="320" controls="controls">
  <source src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/videos/carla_simmul.mp4" type="video/mp4" />
</video>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="deep mind" /><category term="reinforcement learning" /><category term="standford" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Week 1</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-1/" rel="alternate" type="text/html" title="Week 1" /><published>2022-06-23T00:00:00+02:00</published><updated>2022-06-23T00:00:00+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-1</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-1/"><![CDATA[<p>Starting to warming up, as I am currently in the first training period of my thesis, I must read a lot of papers related to the task at hand, understand them and if possible, starting to plan the environment where I can begin to work. Given that the thesis revolves around reinforcement learning, my tutor and advisors kindly pointed me towards DeepMind famous projects, such as <a href="https://www.deepmind.com/research/highlighted-research/alphago">AlphaGo</a> or <a href="https://www.deepmind.com/blog/agent57-outperforming-the-human-atari-benchmark">Agent57</a>.</p>

<p>The thesis, as it is going to involve the control of an autonomous vehicle with the use of reinforcement learning, it would be more advisable to read about Agent57. To vaguely resume it, Agent57 is the latest Deep Reinforcement Learning Agent capable of outperforming the human level on the 57 games that where included in the Atari 2600. A read of the progress made first in 2013 until Agent57 in 2020 gives us a first look at the general picture of how to tackle reinforcement learning problems with state of the art models. I leave the papers below:</p>

<ul>
  <li>2013: <a href="https://arxiv.org/pdf/1312.5602v1.pdf">https://arxiv.org/pdf/1312.5602v1.pdf</a></li>
  <li>2020: <a href="https://arxiv.org/pdf/2003.13350.pdf">https://arxiv.org/pdf/2003.13350.pdf</a></li>
</ul>

<p>As a starting point to learn more deeply about reinforcement learning, an online course is available for free on <a href="https://www.youtube.com/watch?v=FgzM3zpZ55o&amp;list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u">Youtube</a> shared by the Standford University which I find remarkable.</p>

<p>Finally, to start thinking towards the environment, the first thing to have in mind is the world where the agents will move and learn, in other words, the simulation. In this area, there are multiple good options to choose from and which are available for free, but a good first analysis must be made in order to have a good framework that doesn’t fails us further ahead in our project.
The first simulation that came to mind was Carla. This is because I had experienced beforehand (for my bachelor degree final project) with this simulation, but because it is so computationally intensive, a first installation and check in my local machine was necessary.</p>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="deep mind" /><category term="reinforcement learning" /><category term="standford" /><summary type="html"><![CDATA[Starting to warming up, as I am currently in the first training period of my thesis, I must read a lot of papers related to the task at hand, understand them and if possible, starting to plan the environment where I can begin to work. Given that the thesis revolves around reinforcement learning, my tutor and advisors kindly pointed me towards DeepMind famous projects, such as AlphaGo or Agent57.]]></summary></entry><entry><title type="html">Week 0</title><link href="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-0/" rel="alternate" type="text/html" title="Week 0" /><published>2022-06-15T00:00:00+02:00</published><updated>2022-06-15T00:00:00+02:00</updated><id>http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-0</id><content type="html" xml:base="http://localhost:4000/2022-tfm-enrique-shinohara/weekly%20log/week-0/"><![CDATA[<p>Ready, set, go!</p>

<p>With this first entry on my weekly blog, I start my master’s thesis with the objective and hope to learn and solve problems related to autonomous driving using computer vision. This first week, the focus is pointed towards installing and playing with softwares such as <a href="https://classic.gazebosim.org/download">Gazebo</a> (a simulator where we can test our robots virtually) and <a href="http://wiki.ros.org/noetic/Installation/Ubuntu">ROS</a> (Robot Operating System). The installation was pretty straight forward, given that both softwares are currently only officially supported for Ubuntu, the instructions can be followed in their respective homepages.</p>

<p>Finally, we needed to undertand how we were going to do a blog for our thesis. For this, thanks to the feedback provided by my thesis tutor, it was decided to write the blog with Github Pages which start static servers to host website directly from our Github repository. In order to mess with this function I had to clone the following repositories:</p>

<ul>
  <li><a href="https://github.com/JdeRobot/jderobot.github.io">jderobot.github.io</a>: repository of the website of the association of Robotics and Artificial Intelligence, JdeRobot.</li>
  <li><a href="https://github.com/mmistakes/minimal-mistakes">minimal-mistakes</a>: repository of the minimal mistakes Jekyll theme for Github Pages.</li>
</ul>

<p>Both of them having multiple examples in order to know and test functionalities, on my own, of Github Pages and Jekyll Templates for an aesthetically pleasing blog website.</p>

<!-- <p align="center">
<img src="/assets/images/minimal_mistakes.png" width="300">
</p> -->

<!-- ![image-center](http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/minimal_mistakes.png){: .align-center} -->

<figure style="width:50%" class="align-center">
  <img src="http://localhost:4000/2022-tfm-enrique-shinohara/assets/images/minimal_mistakes.png" alt="" />
  <figcaption>Minimal mistakes template for Jekyll</figcaption>
</figure>]]></content><author><name>Enrique Shinohara</name><email>enriqueshino@gmail.com</email></author><category term="Weekly Log" /><category term="github page" /><category term="ros noetic" /><category term="gazebo" /><summary type="html"><![CDATA[Ready, set, go!]]></summary></entry></feed>